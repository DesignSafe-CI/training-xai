
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>XAI Classification of Lateral Spreading &#8212; DesignSafe XAI training</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-X06NJT7GSH"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-X06NJT7GSH');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-X06NJT7GSH');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'xai/01-classification-exercise';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../README.html">
  
  
  
  
  
  
    <p class="title logo__title">DesignSafe XAI training</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../README.html">
                    DesignSafe XAI Training
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="01-classification.html">XAI Classification of Lateral Spreading</a></li>


</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/DesignSafe-CI/2024-xai-course/blob/main/docs/xai/01-classification-exercise.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/DesignSafe-CI/2024-xai-course" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/DesignSafe-CI/2024-xai-course/issues/new?title=Issue%20on%20page%20%2Fxai/01-classification-exercise.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/xai/01-classification-exercise.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>XAI Classification of Lateral Spreading</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">XAI Classification of Lateral Spreading</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-packages">Install packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#liquefaction">Liquefaction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lateral-spreading-classification">Lateral spreading classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explore-data">Explore data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering-for-features">Filtering for features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-testing-and-validation">Training, testing and validation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-classifier">Decision tree classifier</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-decision-trees">Classification: Decision Trees</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gini-impurity">GINI Impurity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-splitting">Decision Tree splitting</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-using-gini-impurity">Example Using Gini Impurity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-with-scikit-learn">Decision tree with SciKit Learn</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">Prediction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-a-decision-tree">Visualizing a decision tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#update-model">Update model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-decision-trees">Summary of decision trees</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost-extreme-gradient-boosting">XGBoost (Extreme Gradient Boosting)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-framework">Gradient Boosting Framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm">Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost-enhancements">XGBoost Enhancements</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-missing-data">Handling Missing Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#column-block-and-parallelization">Column Block and Parallelization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters">Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explainable-ai">Explainable AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-importance-metrics">Feature Importance Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-importance-metrics">Types of Importance Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#weight-based-importance">1. <strong>Weight-Based Importance</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#permutation-importance">2. <strong>Permutation Importance</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shapley-values">3. Shapley Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-shap-values-an-analogy">Understanding SHAP Values: An Analogy</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-project">The Project</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shapley-value-concept">Shapley Value Concept</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-explanation">Step by Step Explanation</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-contributions">Calculating Contributions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#positive-vs-negative-shap-values">Positive vs. Negative SHAP Values</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#positive-prediction">Positive prediction</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-prediction">Negative prediction</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#global-explanation">Global explanation</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="xai-classification-of-lateral-spreading">
<h1>XAI Classification of Lateral Spreading<a class="headerlink" href="#xai-classification-of-lateral-spreading" title="Link to this heading">#</a></h1>
<p><strong>Exercise:</strong>
<a class="reference external" href="https://jupyter.designsafe-ci.org/hub/user-redirect/lab/tree/CommunityData/Training/xai/01-classification-exercise.ipynb"><img alt="Try on DesignSafe" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/DesignSafe-Badge.svg" /></a></p>
<p><strong>Solution:</strong> <a class="reference external" href="https://jupyter.designsafe-ci.org/hub/user-redirect/lab/tree/CommunityData/Training/xai/01-classification.ipynb"><img alt="Try on DesignSafe" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/DesignSafe-Badge.svg" /></a></p>
<section id="install-packages">
<h2>Install packages<a class="headerlink" href="#install-packages" title="Link to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>scikit-learn<span class="w"> </span>pandas<span class="w"> </span>--quiet
<span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>xgboost<span class="w"> </span>--quiet
<span class="o">!</span>pip3<span class="w"> </span>install<span class="w"> </span>shap<span class="w"> </span>--quiet
</pre></div>
</div>
</div>
</div>
</section>
<section id="liquefaction">
<h2>Liquefaction<a class="headerlink" href="#liquefaction" title="Link to this heading">#</a></h2>
<blockquote>
<div><p>Durante, M. G., &amp; Rathje, E. M. (2021). An exploration of the use of machine learning to predict lateral spreading. Earthquake Spectra, 37(4), 2288-2314.</p>
</div></blockquote>
<p>Soil liquefaction is a phenomenon that typically occurs in saturated loose sandy soils subjected to rapid loading conditions, such as earthquakes. The generation of excess pore water pressure is a direct consequence of the rapid loading, which can lead to a sudden reduction in the strength and stiffness of the soil. In the presence of gently sloping ground or near the free face of a slope, the occurrence of earthquake-induced liquefaction may generate lateral displacements, known as lateral spreading.</p>
<p><img alt="liquefaction" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/xai/liquefaction.png" /></p>
<blockquote>
<div><p>Fig: (a) Observed liquefaction-related damage (data from NZGD, 2013), and (b) lateral spreading
horizontal displacement observed from optical image correlation (data from Rathje et al., 2017b) in the
Avon River area for the 2011 Christchurch earthquake</p>
</div></blockquote>
</section>
<section id="lateral-spreading-classification">
<h2>Lateral spreading classification<a class="headerlink" href="#lateral-spreading-classification" title="Link to this heading">#</a></h2>
<p>Durante and Rathje (2021) classified sites that experienced more than 0.3 m displacement as lateral spreading. We now evaluate different factors that influence soil lateral spreading, such as (i) Ground Water Table (ground water closer to surface means more chance of liquefaction), (ii) slope angle (steeper the slope more lateral spreading), (iii) PGA - Peak Ground acceleration (intensity of earthquake shaking), and (iv) elevation (certain sites on high terrace don’t show lateral spreading).</p>
<p><img alt="Factors affecting liquefaction" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/xai/liq-factors.png" /></p>
<blockquote>
<div><p>Image credits: Durante and Rathje (2021).</p>
</div></blockquote>
<section id="explore-data">
<h3>Explore data<a class="headerlink" href="#explore-data" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read data from DesignSafe community data</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Explore your dataset</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="filtering-for-features">
<h3>Filtering for features<a class="headerlink" href="#filtering-for-features" title="Link to this heading">#</a></h3>
<p>Remove any feature in the dataset that we don’t want to include in the training process.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Test ID&#39;</span><span class="p">,</span> <span class="s1">&#39;Elevation&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Target&#39;</span><span class="p">]</span>
<span class="n">y</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="training-testing-and-validation">
<h3>Training, testing and validation<a class="headerlink" href="#training-testing-and-validation" title="Link to this heading">#</a></h3>
<p>When developing a machine learning model, it is common practice to divide the available data into three subsets - training, validation, and testing. This is done to properly assess model performance and generalizability.</p>
<p>The training set is used to fit the parameters of the model. The majority of the data, typically 60-80%, is allocated for training so that the model can learn the underlying patterns.</p>
<p>The validation set is used to tune any hyperparameters of the model and make architectural choices. For example, it helps decide the number of hidden layers and units in a neural network. Typically 20% of data is used for validation.</p>
<p>The test set provides an unbiased evaluation of the fully-trained model’s performance. It is critical for getting an accurate estimate of how the model will work on new unseen data. Usually 20% of the data is reserved for testing.</p>
<p>The splits should be made randomly while ensuring the class distribution is approximately balanced across all sets. No data from the validation or test sets should be used during training. This prevents overfitting and ensures the evaluation reflects real-world performance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># View data before splitting to training and testing</span>
</pre></div>
</div>
</div>
</div>
<p>We are going to use the <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> function twice to split the data into training + validation and testing. Then, we split the <code class="docutils literal notranslate"><span class="pre">training</span> <span class="pre">+</span> <span class="pre">validation</span></code> into training and validation. We retrain the target values for now, so we can check how good is our prediction.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Specify split</span>
<span class="n">X_train_target</span><span class="p">,</span> <span class="n">X_val_test_target</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_val_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="p">)</span>
<span class="n">X_test_target</span><span class="p">,</span> <span class="n">X_val_target</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">y_val</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_val_test_target</span><span class="p">,</span> <span class="n">y_val_test</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_val_target</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train_target</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Target&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test_target</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Target&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X_val</span> <span class="o">=</span> <span class="n">X_val_target</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;Target&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_test</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="decision-tree-classifier">
<h1>Decision tree classifier<a class="headerlink" href="#decision-tree-classifier" title="Link to this heading">#</a></h1>
<section id="classification-decision-trees">
<h2>Classification: Decision Trees<a class="headerlink" href="#classification-decision-trees" title="Link to this heading">#</a></h2>
<p>Classification is the task of predicting a categorical target variable based on input data. There are two main types of classification:</p>
<p><strong>Binary classification</strong>: The target variable has two possible classes, often labeled 0 and 1. The goal is to predict which of the two classes an input belongs to. Examples include spam detection, disease diagnosis, etc.</p>
<p><strong>Multi-class classification</strong>: The target variable has more than two possible discrete values or classes. The goal is to predict the specific class an input belongs to out of the multiple choices. Examples include image recognition, document categorization, etc.</p>
<p>A decision tree is a flowchart-like structure where each internal node represents a test on a feature (e.g., “is feature A &gt; 5?”), each branch represents an outcome of the test, and each leaf node represents a class label. A decision tree is a supervised learning model used for both binary and multi-class classification. It works by recursively partitioning the input space into smaller subspaces based on the value of different predictor variables. The goal is to create leaf nodes that contain cases with similar values of the target variable.</p>
<p>The process of learning a decision tree involves selecting features and split points that best separate the classes, based on a criterion such as information gain or Gini impurity. It continues until a stopping criterion is met, like reaching a maximum depth or a minimum number of samples per leaf.</p>
<p>The structure of a decision tree consists of:</p>
<ul class="simple">
<li><p><strong>Root node</strong>: This is the topmost node in the tree and contains the full dataset.</p></li>
<li><p><strong>Internal nodes</strong>: These represent points where the data is split based on values of predictor variables.</p></li>
<li><p><strong>Branches</strong>: These connect the internal nodesbased on possible values of predictors.</p></li>
<li><p><strong>Leaf nodes</strong>: These represent the final classifications or predictions.</p></li>
</ul>
<p>Decision trees can handle both categorical and continuous predictors.</p>
<p>Some key advantages of decision trees are:</p>
<ul class="simple">
<li><p><strong>Interpretability</strong> - The tree structure and rules are easy to understand.</p></li>
<li><p><strong>Non-parametric</strong> - No assumptions about data distribution.</p></li>
<li><p><strong>Handles nonlinear relationships</strong> - By partitioning data recursively.</p></li>
<li><p><strong>Handles categorical variables</strong> - No need for dummy coding.</p></li>
</ul>
<p><img alt="liquefaction decision tree" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/xai/liq-dt.png" /></p>
<section id="gini-impurity">
<h3>GINI Impurity<a class="headerlink" href="#gini-impurity" title="Link to this heading">#</a></h3>
<p>Gini impurity is used to evaluate how good a split is by calculating the impurity of the subsets resulting from the split. A lower Gini score means that the split is separating the classes well. It quantifies the disorder or uncertainty within a set of data.</p>
<p>The Gini impurity for a binary classification is calculated as:
$<span class="math notranslate nohighlight">\(Gini(t)=1−\sum(p_i)^2\)</span>$</p>
<p>where <span class="math notranslate nohighlight">\(p_i\)</span>​ is the probability of class <span class="math notranslate nohighlight">\(i\)</span> in the set.</p>
</section>
<section id="decision-tree-splitting">
<h3>Decision Tree splitting<a class="headerlink" href="#decision-tree-splitting" title="Link to this heading">#</a></h3>
<p>A decision tree decides a split by selecting a feature and a value to divide the dataset into two or more homogenous subsets, according to a certain criterion. The ultimate goal is to find the splits that produce the purest subsets, meaning that each subset ideally contains data points from only one class. Here’s how it works:</p>
<ul class="simple">
<li><p><strong>Selection of Criteria</strong>: The method used to decide a split depends on the criterion being used. Common criteria for classification tasks include Gini Impurity, Information Gain, and Chi-Squared. For regression tasks, variance reduction is often used.</p></li>
<li><p><strong>Evaluate Each Feature and Potential Split</strong>: For each feature in the dataset, the algorithm calculates the criterion’s value for every potential split point. Split points can be the actual values of a continuous feature or different categories of a categorical feature.</p></li>
<li><p><strong>Choose the Best Split</strong>: The algorithm selects the feature and split point that produces the subsets with the highest purity according to the chosen criterion. For example:
In the case of Gini Impurity, the best split minimizes the impurity.
In the case of Information Gain, the best split maximizes the gain.</p></li>
<li><p><strong>Create Subsets</strong>: Once the best split has been identified, the dataset is divided into subsets according to the chosen feature and split point.</p></li>
<li><p><strong>Repeat</strong>: Steps 1-4 are repeated recursively on each of the subsets until a stopping criterion is met, such as reaching a certain tree depth or the subsets being pure enough.</p></li>
</ul>
<section id="example-using-gini-impurity">
<h4>Example Using Gini Impurity<a class="headerlink" href="#example-using-gini-impurity" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p>For each feature, consider all possible values for splitting.</p></li>
<li><p>Choose the split that results in the lowest weighted Gini Impurity.</p></li>
<li><p>Calculate the Gini Impurity for each possible split as:</p></li>
<li><p>Divide the dataset accordingly and continue the process.</p></li>
</ul>
<p>In the context of decision trees, the splitting process is essential as it helps the model generalize the pattern from the training data, enabling accurate predictions or classifications for unseen data. It’s the core step in building the tree, and different algorithms might have variations in the splitting procedure.</p>
</section>
</section>
</section>
<section id="decision-tree-with-scikit-learn">
<h2>Decision tree with SciKit Learn<a class="headerlink" href="#decision-tree-with-scikit-learn" title="Link to this heading">#</a></h2>
<p>Scikit-learn, often referred to as sklearn, is one of the most popular libraries for machine learning in Python</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">tree</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># View accuracy scores</span>
</pre></div>
</div>
</div>
</div>
<section id="prediction">
<h3>Prediction<a class="headerlink" href="#prediction" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a prediction</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="visualizing-a-decision-tree">
<h3>Visualizing a decision tree<a class="headerlink" href="#visualizing-a-decision-tree" title="Link to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">))</span>
<span class="n">tree</span><span class="o">.</span><span class="n">plot_tree</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span>
               <span class="n">feature_names</span> <span class="o">=</span><span class="p">[</span><span class="s1">&#39;GWD (m)&#39;</span><span class="p">,</span> <span class="s1">&#39;L (km)&#39;</span><span class="p">,</span> <span class="s1">&#39;Slope (%)&#39;</span><span class="p">,</span> <span class="s1">&#39;PGA (g)&#39;</span><span class="p">],</span>
               <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Liquefaction&#39;</span><span class="p">,</span> <span class="s1">&#39;No liquefaction&#39;</span><span class="p">],</span>
               <span class="n">filled</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="update-model">
<h3>Update model<a class="headerlink" href="#update-model" title="Link to this heading">#</a></h3>
<p>We increase the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> to 7 so we have a better fit.</p>
<blockquote>
<div><p>💡 Try varying the <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> from 5 - 9.</p>
</div></blockquote>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Specify depth</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span> <span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="summary-of-decision-trees">
<h3>Summary of decision trees<a class="headerlink" href="#summary-of-decision-trees" title="Link to this heading">#</a></h3>
<p>Pros and Cons</p>
<ul class="simple">
<li><p>Pros: Simple to understand and visualize, able to handle categorical and numerical data.</p></li>
<li><p>Cons: Prone to overfitting, especially when the tree is deep, leading to poor generalization to unseen data. A small change in the data can lead to a very different tree.</p></li>
</ul>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="xgboost-extreme-gradient-boosting">
<h1>XGBoost (Extreme Gradient Boosting)<a class="headerlink" href="#xgboost-extreme-gradient-boosting" title="Link to this heading">#</a></h1>
<p>XGBoost is a popular and efficient gradient boosting framework that’s widely used in machine learning, including in scientific contexts. It builds on the idea of boosting, where weak learners are combined to create a strong learner.</p>
<section id="gradient-boosting-framework">
<h2>Gradient Boosting Framework<a class="headerlink" href="#gradient-boosting-framework" title="Link to this heading">#</a></h2>
<p>Gradient Boosting is an ensemble learning method that fits a sequence of weak learners (such as shallow decision trees) on modified versions of the data.</p>
<p>The general form of the boosting model is:</p>
<div class="math notranslate nohighlight">
\[ f(x) = \sum_{k=1}^K \alpha_k h_k(x) \]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(f(x)\)</span> is the prediction for input <span class="math notranslate nohighlight">\( x \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( \alpha_k \)</span> is the weight of the <span class="math notranslate nohighlight">\( k \)</span>-th weak learner</p></li>
<li><p><span class="math notranslate nohighlight">\( h_k(x) \)</span> is the prediction of the <span class="math notranslate nohighlight">\( k \)</span>-th weak learner</p></li>
<li><p><span class="math notranslate nohighlight">\( K \)</span> is the total number of weak learners</p></li>
</ul>
</section>
<section id="algorithm">
<h2>Algorithm<a class="headerlink" href="#algorithm" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Initialization:</strong> Start with a constant prediction <span class="math notranslate nohighlight">\( f_0(x) \)</span></p></li>
<li><p><strong>Iteratively Add Trees:</strong> For <span class="math notranslate nohighlight">\( k = 1 \)</span> to <span class="math notranslate nohighlight">\( K \)</span>:
a. Compute the negative gradient (or “pseudo-residuals”) of the loss function:
$<span class="math notranslate nohighlight">\( r_i = -\frac{\partial L(y_i, f(x_i))}{\partial f(x_i)} \)</span><span class="math notranslate nohighlight">\(
b. Fit a weak learner to predict the pseudo-residuals.
c. Compute the weight \)</span> \alpha_k <span class="math notranslate nohighlight">\( that minimizes the loss.
d. Update the model by adding the weighted weak learner:
   \)</span><span class="math notranslate nohighlight">\( f_k(x) = f_{k-1}(x) + \alpha_k h_k(x) \)</span>$</p></li>
</ol>
</section>
<section id="xgboost-enhancements">
<h2>XGBoost Enhancements<a class="headerlink" href="#xgboost-enhancements" title="Link to this heading">#</a></h2>
<p>XGBoost adds several enhancements to the basic gradient boosting framework:</p>
<section id="regularization">
<h3>Regularization<a class="headerlink" href="#regularization" title="Link to this heading">#</a></h3>
<p>XGBoost includes L1 (Lasso) and L2 (Ridge) regularization terms in the loss function to prevent overfitting:</p>
<div class="math notranslate nohighlight">
\[ \text{Loss} = L(y, f(x)) + \lambda_1 \sum |\alpha_k| + \lambda_2 \sum \alpha_k^2 \]</div>
</section>
<section id="handling-missing-data">
<h3>Handling Missing Data<a class="headerlink" href="#handling-missing-data" title="Link to this heading">#</a></h3>
<p>XGBoost can automatically learn the best direction to handle missing values during training, allowing it to handle datasets with missing data.</p>
</section>
<section id="column-block-and-parallelization">
<h3>Column Block and Parallelization<a class="headerlink" href="#column-block-and-parallelization" title="Link to this heading">#</a></h3>
<p>XGBoost employs a column block structure that allows parallelization over both instances and features, leading to efficient computation.</p>
</section>
<section id="hyperparameters">
<h3>Hyperparameters<a class="headerlink" href="#hyperparameters" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>learning_rate:</strong> Step size shrinkage to prevent overfitting.</p></li>
<li><p><strong>max_depth:</strong> Maximum depth of the decision trees.</p></li>
<li><p><strong>n_estimators:</strong> Number of boosting rounds.</p></li>
<li><p><strong>subsample:</strong> Fraction of the data to be used for each boosting round, enabling stochastic gradient boosting.</p></li>
</ul>
<p><img alt="XGB" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/xai/xgb.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create and train XGB model</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">xgb</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Validation score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">xgb</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_val</span><span class="p">,</span> <span class="n">y_val</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Testing score: </span><span class="si">%.2f%%</span><span class="s1">&#39;</span> <span class="o">%</span><span class="p">(</span><span class="n">xgb</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="explainable-ai">
<h2>Explainable AI<a class="headerlink" href="#explainable-ai" title="Link to this heading">#</a></h2>
<section id="feature-importance-metrics">
<h3>Feature Importance Metrics<a class="headerlink" href="#feature-importance-metrics" title="Link to this heading">#</a></h3>
<p>Feature importance metrics provide insights into the contribution of individual features (or variables) to a predictive model. Understanding the importance of different features can help in feature selection, model interpretation, and understanding the underlying relationships within the data.</p>
<section id="types-of-importance-metrics">
<h4>Types of Importance Metrics<a class="headerlink" href="#types-of-importance-metrics" title="Link to this heading">#</a></h4>
<section id="weight-based-importance">
<h5>1. <strong>Weight-Based Importance</strong><a class="headerlink" href="#weight-based-importance" title="Link to this heading">#</a></h5>
<p>In models like linear regression or logistic regression, the magnitude of the coefficients can indicate the importance of features. For tree-based models like Random Forest, the importance of a feature can be calculated based on the average gain of the feature when it is used in trees.</p>
</section>
<section id="permutation-importance">
<h5>2. <strong>Permutation Importance</strong><a class="headerlink" href="#permutation-importance" title="Link to this heading">#</a></h5>
<p>Permutation importance is a method that can be applied to any model. It is computed as follows:</p>
<p>a. <strong>Calculate a Performance Metric:</strong> Train the model and calculate a performance metric (such as accuracy or MSE) using a validation set.
b. <strong>Permute the Feature Values:</strong> Shuffle the values of the feature of interest across the validation set, destroying the relationship between the feature and the target.
c. <strong>Recompute the Performance Metric:</strong> Use the permuted data to compute the performance metric again.
d. <strong>Calculate Importance:</strong> The difference between the original metric and the permuted metric provides a measure of importance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="c1">## Compute feature importance for random forest</span>
<span class="k">def</span> <span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
    <span class="n">df2</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">df2</span><span class="o">.</span><span class="n">columns</span>
    <span class="n">importances</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">importances</span><span class="p">)[</span><span class="o">-</span><span class="mi">10</span><span class="p">:]</span>  <span class="c1"># top 10 features</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Feature Importances&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)),</span> <span class="n">importances</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)),</span> <span class="p">[</span><span class="n">features</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Relative Importance&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

    <span class="n">fi</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="nb">list</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="p">),</span>
                       <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">})</span><span class="o">.</span>\
                       <span class="n">sort_values</span><span class="p">(</span><span class="s1">&#39;importance&#39;</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fi</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display results for decision tree</span>
<span class="n">plot_feature_importance</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Display results for XGB</span>
<span class="n">plot_feature_importance</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">xgb</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section id="shapley-values">
<h3>3. Shapley Values<a class="headerlink" href="#shapley-values" title="Link to this heading">#</a></h3>
<p>SHAP values are based on cooperative game theory and provide a unified measure of feature importance. They give the average contribution of a feature value to every possible prediction.</p>
<p>For a model with <span class="math notranslate nohighlight">\(M\)</span> features, the Shapley value for feature <span class="math notranslate nohighlight">\( i \)</span> is computed as:</p>
<div class="math notranslate nohighlight">
\[ \phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!(M - |S| - 1)!}{M!} [v(S \cup \{i\}) - v(S)] \]</div>
<p>Where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\( S \)</span> is a subset of features excluding feature <span class="math notranslate nohighlight">\( i \)</span></p></li>
<li><p><span class="math notranslate nohighlight">\( N \)</span> is the set of all features</p></li>
<li><p><span class="math notranslate nohighlight">\( v(S) \)</span> is the value function that gives the prediction for subset <span class="math notranslate nohighlight">\( S \)</span></p></li>
</ul>
</section>
<section id="understanding-shap-values-an-analogy">
<h3>Understanding SHAP Values: An Analogy<a class="headerlink" href="#understanding-shap-values-an-analogy" title="Link to this heading">#</a></h3>
<p>SHAP values help us understand how different features (or variables) contribute to a prediction in a machine learning model. To explain this without mathematics, let’s use an analogy of three team members working together on a project. Imagine that the team members are Alice, Bob, and Charlie, and we want to know how much each one contributed to the project’s success.</p>
<section id="the-project">
<h4>The Project<a class="headerlink" href="#the-project" title="Link to this heading">#</a></h4>
<p>The project’s success is measured by the total output, and we want to fairly distribute the credit for this success among Alice, Bob, and Charlie.</p>
</section>
<section id="shapley-value-concept">
<h4>Shapley Value Concept<a class="headerlink" href="#shapley-value-concept" title="Link to this heading">#</a></h4>
<p>Imagine breaking down the project into smaller tasks and observing how much the output changes when each team member is added or removed. The goal is to find the average contribution of each member over all possible ways the team could have been formed.</p>
<section id="step-by-step-explanation">
<h5>Step by Step Explanation<a class="headerlink" href="#step-by-step-explanation" title="Link to this heading">#</a></h5>
<ol class="arabic simple">
<li><p><strong>No Team Members:</strong> First, we measure the output with no team members working (a baseline).</p></li>
<li><p><strong>Adding One Member:</strong> Then, we add each team member one by one and measure how much the output changes.</p>
<ul class="simple">
<li><p>With Alice alone</p></li>
<li><p>With Bob alone</p></li>
<li><p>With Charlie alone</p></li>
</ul>
</li>
<li><p><strong>Adding Two Members:</strong> Next, we measure the change in output with pairs of team members:</p>
<ul class="simple">
<li><p>Alice and Bob</p></li>
<li><p>Alice and Charlie</p></li>
<li><p>Bob and Charlie</p></li>
</ul>
</li>
<li><p><strong>All Three Members:</strong> Finally, we measure the output with all three working together.</p></li>
</ol>
</section>
</section>
<section id="calculating-contributions">
<h4>Calculating Contributions<a class="headerlink" href="#calculating-contributions" title="Link to this heading">#</a></h4>
<p>By comparing all these different combinations, we can calculate the average contribution of each team member. The SHAP value for each person is their fair share of the contribution to the project’s success.</p>
<ul class="simple">
<li><p><strong>Alice’s SHAP Value:</strong> The average change in output when Alice is part of the team.</p></li>
<li><p><strong>Bob’s SHAP Value:</strong> The average change in output when Bob is part of the team.</p></li>
<li><p><strong>Charlie’s SHAP Value:</strong> The average change in output when Charlie is part of the team.</p></li>
</ul>
<p><img alt="Shapley" src="https://raw.githubusercontent.com/DesignSafe-Training/xai/main/xai/shap.png" /></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">shap</span>
<span class="c1"># Create explanations</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test_target</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>SHAP values are a measure used to explain the output of machine learning models. They tell us how much each feature in the model contributes to a particular prediction, compared to a baseline prediction.</p>
</section>
<section id="positive-vs-negative-shap-values">
<h4>Positive vs. Negative SHAP Values<a class="headerlink" href="#positive-vs-negative-shap-values" title="Link to this heading">#</a></h4>
<ul class="simple">
<li><p><strong>Positive SHAP Values:</strong> When a feature has a positive SHAP value, it means that the presence (or value) of that feature pushes the model’s output higher than the baseline.</p>
<ul>
<li><p><strong>Example:</strong> In our lateral spreading prediction the PGA (a feature) gives a positive SHAP value, it means that higher PGA are generally associated with higher chance of lateral spreading.</p></li>
</ul>
</li>
<li><p><strong>Negative SHAP Values:</strong> Conversely, when a feature has a negative SHAP value, it means that the presence (or value) of that feature pushes the model’s output lower than the baseline.</p>
<ul>
<li><p><strong>Example:</strong> Still considering lateral spreading, if water table being too low (a feature) gives a negative SHAP value, it suggests that such sites are generally predicted to have less chance of lateral spreading.</p></li>
</ul>
</li>
</ul>
<p>The term <span class="math notranslate nohighlight">\(E(f(x))\)</span> represents the expected value or average prediction of the model over the entire dataset. Think of it as the “baseline prediction.” When you see <span class="math notranslate nohighlight">\(E(f(x))\)</span> , it’s referring to what the model would predict on average, without considering any specific feature values.</p>
<ul class="simple">
<li><p><strong>Example:</strong> In the context of predicting house prices, <span class="math notranslate nohighlight">\(E(f(x))\)</span>  might be the average chance of lateral spreading the model predicts when it doesn’t consider any specific features of the sites. It’s the starting point before we account for unique factors like having GWT or a high PGA.</p></li>
</ul>
</section>
<section id="positive-prediction">
<h4>Positive prediction<a class="headerlink" href="#positive-prediction" title="Link to this heading">#</a></h4>
<p>In this example, we show a site that is predicted to have positive lateral spreading (failure). Here, the high slope anlge (0.835%) has the most influence in the positive prediction of lateral spreading, followed by a shallow ground water depth of 1.8 m and its close proximity to the river (L = 0.74 km).</p>
</section>
<section id="negative-prediction">
<h4>Negative prediction<a class="headerlink" href="#negative-prediction" title="Link to this heading">#</a></h4>
<p>In this example, we show XGB predicting a site that has no chance of lateral spreading. The distance to the river (L ~ 2 km) seems to be the primary reason.</p>
</section>
</section>
<section id="global-explanation">
<h3>Global explanation<a class="headerlink" href="#global-explanation" title="Link to this heading">#</a></h3>
<p>We also observe global SHAP values and see how different features influence the results. High feature values are shown in red and Low feature values are shown in blue. For e.g., shorter distance to the river (blue points for <span class="math notranslate nohighlight">\(L\)</span>) are associated with high chance of lateral spreading. Similarly, deeper ground water depth (red GWD) means lower chances of lateral spreading.</p>
<p>However, we do see that high PGA, shows less chance of lateral spreading, contradictory to the engineering understanding that high acceleration will cause more displacements and failures.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./xai"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">XAI Classification of Lateral Spreading</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#install-packages">Install packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#liquefaction">Liquefaction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#lateral-spreading-classification">Lateral spreading classification</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#explore-data">Explore data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#filtering-for-features">Filtering for features</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#training-testing-and-validation">Training, testing and validation</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-classifier">Decision tree classifier</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#classification-decision-trees">Classification: Decision Trees</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gini-impurity">GINI Impurity</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-splitting">Decision Tree splitting</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example-using-gini-impurity">Example Using Gini Impurity</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#decision-tree-with-scikit-learn">Decision tree with SciKit Learn</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#prediction">Prediction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#visualizing-a-decision-tree">Visualizing a decision tree</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#update-model">Update model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#summary-of-decision-trees">Summary of decision trees</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost-extreme-gradient-boosting">XGBoost (Extreme Gradient Boosting)</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gradient-boosting-framework">Gradient Boosting Framework</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm">Algorithm</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#xgboost-enhancements">XGBoost Enhancements</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#regularization">Regularization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#handling-missing-data">Handling Missing Data</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#column-block-and-parallelization">Column Block and Parallelization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hyperparameters">Hyperparameters</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#explainable-ai">Explainable AI</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#feature-importance-metrics">Feature Importance Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#types-of-importance-metrics">Types of Importance Metrics</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#weight-based-importance">1. <strong>Weight-Based Importance</strong></a></li>
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#permutation-importance">2. <strong>Permutation Importance</strong></a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#shapley-values">3. Shapley Values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#understanding-shap-values-an-analogy">Understanding SHAP Values: An Analogy</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-project">The Project</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shapley-value-concept">Shapley Value Concept</a><ul class="nav section-nav flex-column">
<li class="toc-h5 nav-item toc-entry"><a class="reference internal nav-link" href="#step-by-step-explanation">Step by Step Explanation</a></li>
</ul>
</li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#calculating-contributions">Calculating Contributions</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#positive-vs-negative-shap-values">Positive vs. Negative SHAP Values</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#positive-prediction">Positive prediction</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#negative-prediction">Negative prediction</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#global-explanation">Global explanation</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Krishna Kumar
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2024.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>